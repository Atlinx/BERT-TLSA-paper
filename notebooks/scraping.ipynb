{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwdIxdbsvqd8"
   },
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrf0ICFIvyDe"
   },
   "source": [
    "## Metacritic\n",
    "\n",
    "Scrapes the games from `metacritic_games.txt` on https://metacritic.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 62,
     "status": "error",
     "timestamp": 1745251219200,
     "user": {
      "displayName": "Alan Tong",
      "userId": "03716925106405979037"
     },
     "user_tz": 240
    },
    "id": "S3gEW7W5s9nd",
    "outputId": "48098336-f9a1-4e25-96bf-45ae59981233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT module_path:  c:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\n",
      "Scraping Metacritic...\n",
      "    minecraft                                200 reviews          (1/110) games\n",
      "    a-short-hike                             110 reviews          (2/110) games\n",
      "    shovel-knight                            88 reviews           (3/110) games\n",
      "    celeste                                  200 reviews          (4/110) games\n",
      "    hollow-knight                            150 reviews          (5/110) games\n",
      "    doki-doki-literature-club-plus           42 reviews           (6/110) games\n",
      "    undertale                                200 reviews          (7/110) games\n",
      "    mortal-kombat-11                         200 reviews          (8/110) games\n",
      "    guilty-gear-strive-                      38 reviews           (9/110) games\n",
      "    guilty-gear-xrd-revelator-               21 reviews           (10/110) games\n",
      "    injustice-2                              160 reviews          (11/110) games\n",
      "    street-fighter-6                         200 reviews          (12/110) games\n",
      "    tekken-8                                 200 reviews          (13/110) games\n",
      "    stardew-valley                           200 reviews          (14/110) games\n",
      "    terraria                                 78 reviews           (15/110) games\n",
      "    dead-space-3                             150 reviews          (16/110) games\n",
      "    halo-combat-evolved                      200 reviews          (17/110) games\n",
      "    halo-3                                   200 reviews          (18/110) games\n",
      "    halo-4                                   200 reviews          (19/110) games\n",
      "    halo-wars-2                              140 reviews          (20/110) games\n",
      "    brawl-stars                              200 reviews          (21/110) games\n",
      "    clash-of-clans                           142 reviews          (22/110) games\n",
      "    outer-wilds                              200 reviews          (23/110) games\n",
      "    hotline-miami                            100 reviews          (24/110) games\n",
      "    hotline-miami-2-wrong-number             182 reviews          (25/110) games\n",
      "    super-mario-bros-wonder                  200 reviews          (26/110) games\n",
      "    risk-of-rain                             79 reviews           (27/110) games\n",
      "    risk-of-rain-2                           144 reviews          (28/110) games\n",
      "    fez                                      96 reviews           (29/110) games\n",
      "    spelunky                                 28 reviews           (30/110) games\n",
      "    spelunky-2                               30 reviews           (31/110) games\n",
      "    cave-story-plus                          36 reviews           (32/110) games\n",
      "    five-nights-at-freddys                   200 reviews          (33/110) games\n",
      "    hades                                    150 reviews          (34/110) games\n",
      "    subnautica                               200 reviews          (35/110) games\n",
      "    subnautica-below-zero                    95 reviews           (36/110) games\n",
      "    enter-the-gungeon                        43 reviews           (37/110) games\n",
      "    exit-the-gungeon                         7 reviews            (38/110) games\n",
      "    zenless-zone-zero                        200 reviews          (39/110) games\n",
      "    genshin-impact                           200 reviews          (40/110) games\n",
      "    wuthering-waves                          134 reviews          (41/110) games\n",
      "    super-mario-maker-2                      200 reviews          (42/110) games\n",
      "    animal-well                              102 reviews          (43/110) games\n",
      "    miside                                   42 reviews           (44/110) games\n",
      "    disco-elysium                            200 reviews          (45/110) games\n",
      "    slime-rancher                            71 reviews           (46/110) games\n",
      "    ori-and-the-blind-forest                 200 reviews          (47/110) games\n",
      "    ori-and-the-will-of-the-wisps            200 reviews          (48/110) games\n",
      "    assassins-creed-origins                  200 reviews          (49/110) games\n",
      "    call-of-duty-modern-warfare-3            150 reviews          (50/110) games\n",
      "    call-of-duty-4-modern-warfare            150 reviews          (51/110) games\n",
      "    call-of-duty-modern-warfare              200 reviews          (52/110) games\n",
      "    tom-clancys-rainbow-six-siege            200 reviews          (53/110) games\n",
      "    counter-strike-2                         200 reviews          (54/110) games\n",
      "    dota-2                                   200 reviews          (55/110) games\n",
      "    league-of-legends                        200 reviews          (56/110) games\n",
      "    path-of-exile                            200 reviews          (57/110) games\n",
      "    firewatch                                200 reviews          (58/110) games\n",
      "    katana-zero                              120 reviews          (59/110) games\n",
      "    super-meat-boy                           94 reviews           (60/110) games\n",
      "    oneshot                                  85 reviews           (61/110) games\n",
      "    papers-please                            150 reviews          (62/110) games\n",
      "    overwatch                                200 reviews          (63/110) games\n",
      "    overwatch-2                              200 reviews          (64/110) games\n",
      "    team-fortress-2                          200 reviews          (65/110) games\n",
      "    apex-legends                             200 reviews          (66/110) games\n",
      "    fortnite                                 200 reviews          (67/110) games\n",
      "    playerunknowns-battlegrounds             200 reviews          (68/110) games\n",
      "    animal-crossing-new-horizons             200 reviews          (69/110) games\n",
      "    cyberpunk-2077                           150 reviews          (70/110) games\n",
      "    valorant                                 200 reviews          (71/110) games\n",
      "    elden-ring                               200 reviews          (72/110) games\n",
      "    wii-sports                               146 reviews          (73/110) games\n",
      "    wii-sports-resort                        95 reviews           (74/110) games\n",
      "    nintendo-switch-sports                   183 reviews          (75/110) games\n",
      "    super-mario-64                           123 reviews          (76/110) games\n",
      "    marvel-rivals                            128 reviews          (77/110) games\n",
      "    the-sims-4                               200 reviews          (78/110) games\n",
      "    super-mario-odyssey                      200 reviews          (79/110) games\n",
      "    rocket-league                            200 reviews          (80/110) games\n",
      "    grand-theft-auto-4                       0 reviews            (81/110) games\n",
      "    world-of-warcraft                        150 reviews          (82/110) games\n",
      "    borderlands-2                            150 reviews          (83/110) games\n",
      "    destiny                                  150 reviews          (84/110) games\n",
      "    destiny-2                                200 reviews          (85/110) games\n",
      "    warframe                                 100 reviews          (86/110) games\n",
      "    super-smash-bros-ultimate                200 reviews          (87/110) games\n",
      "    god-of-war-ragnarok                      200 reviews          (88/110) games\n",
      "    hearthstone-heroes-of-warcraft           200 reviews          (89/110) games\n",
      "    pokemon-tcg-pocket                       13 reviews           (90/110) games\n",
      "    pokemon-legends-arceus                   200 reviews          (91/110) games\n",
      "    tetris-effect                            56 reviews           (92/110) games\n",
      "    the-last-of-us-part-ii                   200 reviews          (93/110) games\n",
      "    the-last-of-us                           200 reviews          (94/110) games\n",
      "    fifa-22                                  200 reviews          (95/110) games\n",
      "    madden-nfl-22                            150 reviews          (96/110) games\n",
      "    madden-nfl-23                            163 reviews          (97/110) games\n",
      "    among-us                                 166 reviews          (98/110) games\n",
      "    rimworld                                 100 reviews          (99/110) games\n",
      "    balatro                                  139 reviews          (100/110) games\n",
      "    satisfactory                             67 reviews           (101/110) games\n",
      "    monster-hunter-wilds                     200 reviews          (102/110) games\n",
      "    stellaris                                150 reviews          (103/110) games\n",
      "    payday-2                                 100 reviews          (104/110) games\n",
      "    delta-force                              13 reviews           (105/110) games\n",
      "    rust                                     200 reviews          (106/110) games\n",
      "    war-thunder                              200 reviews          (107/110) games\n",
      "    world-of-tanks                           200 reviews          (108/110) games\n",
      "    sid-meiers-civilization-vi               200 reviews          (109/110) games\n",
      "    helldivers-2                             200 reviews          (110/110) games\n",
      "Total review count: 16699\n",
      "Time elapsed: 382.08242959999916 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(\"INIT module_path: \", module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "DATA_DIR = module_path + \"/data\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote import webelement\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import bs4\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def scrape_metacritic_reviews(reviews_per_game: int = 200, games_file: str = \"metacritic_games.txt\", out_file: str = \"metacritic_reviews.csv\"):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    games = []\n",
    "    with open(f\"{DATA_DIR}/{games_file}\", \"r\") as out_file:\n",
    "        games = out_file.read().splitlines()\n",
    "\n",
    "    rows_list: list[list] = []\n",
    "    def scrape_game(i: int, game: str):\n",
    "        nonlocal rows_list\n",
    "        driver.get(f\"https://www.metacritic.com/game/{game}/user-reviews\")\n",
    "        # Scroll until we get >= MAX_REVIEWS_PER_GAME \n",
    "        SCROLL_PAUSE_TIME = 0.5\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        elems: list[webelement.WebElement] = []\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            elems = driver.find_elements(By.CSS_SELECTOR, \"div[data-testid='product-review']\")\n",
    "            if new_height == last_height or len(elems) >= reviews_per_game:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Use BeautifulSoup to do actual parsing, since it's way faster\n",
    "        soup = bs4.BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        all_reviews = soup.find_all(\"div\", {\"data-testid\": \"product-review\"})[:reviews_per_game]\n",
    "        for elem in all_reviews:\n",
    "            user = elem.find(\"a\", \"c-siteReviewHeader_username\").text\n",
    "            review_score = elem.find(\"div\", \"c-siteReviewScore\").find(\"span\").text\n",
    "            review = elem.find(\"div\", \"c-siteReview_quote\").find(\"span\").text\n",
    "            rows_list.append([\"metacritic\", user.strip(), game, review.strip(), review_score.strip(), \"10\"])\n",
    "        print(f\"    {game:<40} {f'{len(all_reviews)} reviews':<20} ({i + 1}/{len(games)}) games\")\n",
    "        \n",
    "    start_pc = time.perf_counter()\n",
    "    print(f\"Scraping Metacritic ({len(games)} games):\")\n",
    "    print(f\"  games_file: {games_file}\")\n",
    "    print(f\"  out_file: {out_file}\")\n",
    "    for i, game in enumerate(games):\n",
    "        scrape_game(i, game)\n",
    "    end_pc = time.perf_counter()\n",
    "    print(f\"Total review count: {len(rows_list)}\")\n",
    "    print(f\"Time elapsed: {end_pc - start_pc} seconds\")\n",
    "\n",
    "    df = pd.DataFrame(rows_list, columns=['site', 'user', 'review_target', 'review', 'score', 'max_score'])\n",
    "    df.to_csv(f\"{DATA_DIR}/{out_file}\", index=False)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "scrape_metacritic_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steam\n",
    "\n",
    "Scrapes the games from `steam_games.txt` on https://steamcommunity.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT module_path:  c:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\n",
      "Scraping Steam (110 games):\n",
      "  games_file: steam_games.csv\n",
      "  out_file: steam_reviews.csv\n",
      "    Schedule I                               200 reviews          (1/110) games\n",
      "    Counter-Strike 2                         200 reviews          (2/110) games\n",
      "    R.E.P.O.                                 200 reviews          (3/110) games\n",
      "    RuneScape: Dragonwilds                   200 reviews          (4/110) games\n",
      "    Marvel Rivals                            200 reviews          (5/110) games\n",
      "    The Last of Us™ Part II Remastered       200 reviews          (6/110) games\n",
      "    Warframe                                 200 reviews          (7/110) games\n",
      "    Baldur's Gate 3                          200 reviews          (8/110) games\n",
      "    Last Epoch                               200 reviews          (9/110) games\n",
      "    Tom Clancy's Rainbow Six® Siege          200 reviews          (10/110) games\n",
      "    Tempest Rising                           200 reviews          (11/110) games\n",
      "    Blue Prince                              200 reviews          (12/110) games\n",
      "    Split Fiction                            200 reviews          (13/110) games\n",
      "    The Elder Scrolls® Online                200 reviews          (14/110) games\n",
      "    War Thunder                              200 reviews          (15/110) games\n",
      "    Warhammer 40,000: Space Marine 2         200 reviews          (16/110) games\n",
      "    Monster Hunter Wilds                     200 reviews          (17/110) games\n",
      "    Dead by Daylight                         200 reviews          (18/110) games\n",
      "    inZOI                                    200 reviews          (19/110) games\n",
      "    Lords of the Fallen                      200 reviews          (20/110) games\n",
      "    HELLDIVERS™ 2                            200 reviews          (21/110) games\n",
      "    Assassin’s Creed Shadows                 200 reviews          (22/110) games\n",
      "    THRONE AND LIBERTY                       200 reviews          (23/110) games\n",
      "    Apex Legends™                            200 reviews          (24/110) games\n",
      "    FATAL FURY: City of the Wolves           193 reviews          (25/110) games\n",
      "    ELDEN RING                               200 reviews          (26/110) games\n",
      "    Drive Beyond Horizons                    200 reviews          (27/110) games\n",
      "    Path of Exile 2                          200 reviews          (28/110) games\n",
      "    Kingdom Come: Deliverance II             200 reviews          (29/110) games\n",
      "    Rust                                     200 reviews          (30/110) games\n",
      "    The Last of Us™ Part I                   200 reviews          (31/110) games\n",
      "    The Sims™ 4                              200 reviews          (32/110) games\n",
      "    FINAL FANTASY XIV Online                 200 reviews          (33/110) games\n",
      "    Fallout 76                               200 reviews          (34/110) games\n",
      "    Delta Force                              200 reviews          (35/110) games\n",
      "    MapleStory                               200 reviews          (36/110) games\n",
      "    Ready or Not                             200 reviews          (37/110) games\n",
      "    The First Berserker: Khazan              200 reviews          (38/110) games\n",
      "    Destiny 2                                200 reviews          (39/110) games\n",
      "    PGA TOUR 2K25                            200 reviews          (40/110) games\n",
      "    Cyberpunk 2077                           200 reviews          (41/110) games\n",
      "    The Outlast Trials                       200 reviews          (42/110) games\n",
      "    Arma Reforger                            200 reviews          (43/110) games\n",
      "    FragPunk                                 200 reviews          (44/110) games\n",
      "    IdleOn - The Idle RPG                    200 reviews          (45/110) games\n",
      "    PUBG: BATTLEGROUNDS                      200 reviews          (46/110) games\n",
      "    Yu-Gi-Oh! Master Duel                    200 reviews          (47/110) games\n",
      "    Call of Duty®: Black Ops III             200 reviews          (48/110) games\n",
      "    Call of Duty®: Black Ops 6               0 reviews            (49/110) games\n",
      "    Diablo® IV                               200 reviews          (50/110) games\n",
      "    Stellaris                                200 reviews          (51/110) games\n",
      "    Crusader Kings III                       200 reviews          (52/110) games\n",
      "    DayZ                                     200 reviews          (53/110) games\n",
      "    Magic: The Gathering Arena               200 reviews          (54/110) games\n",
      "    Team Fortress 2                          200 reviews          (55/110) games\n",
      "    Black Desert                             200 reviews          (56/110) games\n",
      "    Phasmophobia                             200 reviews          (57/110) games\n",
      "    NBA 2K25                                 200 reviews          (58/110) games\n",
      "    Once Human                               200 reviews          (59/110) games\n",
      "    American Truck Simulator                 200 reviews          (60/110) games\n",
      "    Planet Zoo                               200 reviews          (61/110) games\n",
      "    Abiotic Factor                           200 reviews          (62/110) games\n",
      "    Disney Dreamlight Valley                 200 reviews          (63/110) games\n",
      "    Sid Meier's Civilization VII             200 reviews          (64/110) games\n",
      "    Balatro                                  200 reviews          (65/110) games\n",
      "    Enshrouded                               200 reviews          (66/110) games\n",
      "    VRChat                                   200 reviews          (67/110) games\n",
      "    WWE 2K25                                 200 reviews          (68/110) games\n",
      "    Stardew Valley                           200 reviews          (69/110) games\n",
      "    EA SPORTS FC™ 25                         200 reviews          (70/110) games\n",
      "    iRacing                                  200 reviews          (71/110) games\n",
      "    No More Room in Hell 2                   200 reviews          (72/110) games\n",
      "    Call of Duty®                            200 reviews          (73/110) games\n",
      "    The Elder Scrolls V: Skyrim Special Edition 200 reviews          (74/110) games\n",
      "    Lost Ark                                 200 reviews          (75/110) games\n",
      "    Dota 2                                   200 reviews          (76/110) games\n",
      "    Call of Duty®: Black Ops II              200 reviews          (77/110) games\n",
      "    BeamNG.drive                             200 reviews          (78/110) games\n",
      "    The First Descendant                     200 reviews          (79/110) games\n",
      "    Marvel's Spider-Man 2                    200 reviews          (80/110) games\n",
      "    Red Dead Redemption 2                    200 reviews          (81/110) games\n",
      "    Call of Duty®: Warzone™                  0 reviews            (82/110) games\n",
      "    RimWorld                                 200 reviews          (83/110) games\n",
      "    7 Days to Die                            200 reviews          (84/110) games\n",
      "    Grand Theft Auto V Enhanced              200 reviews          (85/110) games\n",
      "    Tom Clancy’s The Division® 2             200 reviews          (86/110) games\n",
      "    Hearts of Iron IV                        200 reviews          (87/110) games\n",
      "    Bodycam                                  200 reviews          (88/110) games\n",
      "    ARK: Survival Ascended                   200 reviews          (89/110) games\n",
      "    Factorio                                 200 reviews          (90/110) games\n",
      "    Sons Of The Forest                       200 reviews          (91/110) games\n",
      "    South of Midnight                        200 reviews          (92/110) games\n",
      "    Satisfactory                             200 reviews          (93/110) games\n",
      "    Farming Simulator 25                     200 reviews          (94/110) games\n",
      "    THE FINALS                               200 reviews          (95/110) games\n",
      "    Forza Horizon 5                          200 reviews          (96/110) games\n",
      "    Sea of Thieves: 2025 Edition             200 reviews          (97/110) games\n",
      "    STAR WARS™: The Old Republic™            200 reviews          (98/110) games\n",
      "    Dark and Darker                          200 reviews          (99/110) games\n",
      "    Black Myth: Wukong                       200 reviews          (100/110) games\n",
      "    World of Warships                        200 reviews          (101/110) games\n",
      "    LUNAR Remastered Collection              172 reviews          (102/110) games\n",
      "    theHunter: Call of the Wild™             200 reviews          (103/110) games\n",
      "    Jurassic World Evolution 2               200 reviews          (104/110) games\n",
      "    Clair Obscur: Expedition 33              0 reviews            (105/110) games\n",
      "    DREDGE                                   200 reviews          (106/110) games\n",
      "    Palworld                                 200 reviews          (107/110) games\n",
      "    Total War: WARHAMMER III                 200 reviews          (108/110) games\n",
      "    Nubby's Number Factory                   200 reviews          (109/110) games\n",
      "    Ghost of Tsushima DIRECTOR'S CUT         200 reviews          (110/110) games\n",
      "Total review count: 0\n",
      "Time elapsed: 1709.9394715000017 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(\"INIT module_path: \", module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "DATA_DIR = module_path + \"/data\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote import webelement\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import bs4\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def scrape_steam_games(count: int = 100, file: str = \"steam_games.csv\"):\n",
    "    start_pc = time.perf_counter()\n",
    "    \n",
    "    print(f\"Scraping top {count} Steam games...\")\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(\"https://store.steampowered.com/search?category1=998&supportedlang=english&ndl=1\")\n",
    "    \n",
    "    # Scroll until we get >= count \n",
    "    SCROLL_PAUSE_TIME = 0.5\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    elems: list[webelement.WebElement] = []\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        elems = driver.find_elements(By.CSS_SELECTOR, \"a[data-ds-appid]\")\n",
    "        if new_height == last_height or len(elems) >= count:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    # Use BeautifulSoup to do actual parsing, since it's way faster\n",
    "    soup = bs4.BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    all_games = soup.find_all(\"a\", {\"data-ds-appid\": True})[:count]\n",
    "    \n",
    "    rows_list: list[list] = []\n",
    "    for game in all_games:\n",
    "        name = game.select_one(\"div > div > span.title\").text\n",
    "        app_id = game[\"data-ds-appid\"]\n",
    "        rows_list.append([name, app_id])\n",
    "\n",
    "    df = pd.DataFrame(rows_list, columns=['name', 'app_id'])\n",
    "    df.to_csv(f\"{DATA_DIR}/{file}\", index=False)\n",
    "\n",
    "    end_pc = time.perf_counter()\n",
    "    print(f\"Total games count: {len(rows_list)}\")\n",
    "    print(f\"Time elapsed: {end_pc - start_pc} seconds\")\n",
    "\n",
    "    driver.quit() \n",
    "\n",
    "\n",
    "def scrape_steam_reviews(reviews_per_game: int = 200, games_file: str = \"steam_games.csv\", out_file: str = \"steam_reviews.csv\"):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    games_df = pd.read_csv(f\"{DATA_DIR}/{games_file}\")\n",
    "   \n",
    "    total_review_count = 0\n",
    "    def scrape_game(i: int, game: str, app_id: str):\n",
    "        nonlocal total_review_count, reviews_per_game, games_df\n",
    "        driver.get(f\"https://steamcommunity.com/app/{app_id}/reviews/?p=1&browsefilter=toprated\")\n",
    "\n",
    "        try:\n",
    "            filter_content = driver.find_element(By.CSS_SELECTOR, \".contentcheck_btns_ctn > button[data-panel]\")\n",
    "            filter_content.click()\n",
    "            time.sleep(0.5)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "        all_reviews = []\n",
    "        curr_rows_list = []\n",
    "        if \"/reviews\" in driver.current_url:\n",
    "            # Scroll until we get >= MAX_REVIEWS_PER_GAME \n",
    "            SCROLL_PAUSE_TIME = 0.5\n",
    "            LOAD_INTERVAL = 0.2\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            elems: list[webelement.WebElement] = []\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                time.sleep(SCROLL_PAUSE_TIME)\n",
    "                \n",
    "                # Idle while we are still loading:\n",
    "                is_loading = True\n",
    "                while is_loading:\n",
    "                    time.sleep(LOAD_INTERVAL)\n",
    "                    wait_elem = driver.find_element(By.CSS_SELECTOR, \".apphub_GetMoreContentWait\")\n",
    "                    is_loading = wait_elem.get_attribute(\"style\").strip() != \"display: none;\"\n",
    "\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                elems = driver.find_elements(By.CSS_SELECTOR, \".apphub_Card\")\n",
    "                if new_height == last_height or len(elems) >= reviews_per_game:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Use BeautifulSoup to do actual parsing, since it's way faster\n",
    "            soup = bs4.BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            all_reviews = soup.find_all(\"div\", \"apphub_Card\")[:reviews_per_game]\n",
    "            for elem in all_reviews:\n",
    "                user = elem.select_one(\".apphub_CardContentAuthorName\").text\n",
    "                review_score = 1 if elem.select_one(\".reviewInfo > .title\").text == \"Recommended\" else 0\n",
    "                \n",
    "                text_content_elem = elem.select_one(\".apphub_CardTextContent\")\n",
    "                for s in text_content_elem.find_all('div'):\n",
    "                    # Remove any non-review info, like early access and posted date\n",
    "                    s.extract()\n",
    "                review = text_content_elem.text\n",
    "\n",
    "                curr_rows_list.append([\"steam\", user.strip(), game, review.strip(), review_score, \"1\"])\n",
    "        print(f\"    {game:<40} {f'{len(all_reviews)} reviews':<20} ({i + 1}/{len(games_df)}) games\")\n",
    "        total_review_count += len(all_reviews)\n",
    "\n",
    "        df = pd.DataFrame(curr_rows_list, columns=['site', 'user', 'review_target', 'review', 'score', 'max_score'])\n",
    "        if i == 0:\n",
    "            # Overwrite the file and add a header if we are the first game is be written\n",
    "            df.to_csv(f\"{DATA_DIR}/{out_file}\", index=False, header=True, mode=\"w\")\n",
    "        else:\n",
    "            df.to_csv(f\"{DATA_DIR}/{out_file}\", index=False, header=False, mode=\"a\")\n",
    "        \n",
    "    start_pc = time.perf_counter()\n",
    "    print(f\"Scraping Steam ({len(games_df)} games):\")\n",
    "    print(f\"  games_file: {games_file}\")\n",
    "    print(f\"  out_file: {out_file}\")\n",
    "    for i, row in games_df.iterrows():\n",
    "        scrape_game(i, row[\"name\"], row[\"app_id\"])\n",
    "\n",
    "    \n",
    "    end_pc = time.perf_counter()\n",
    "    print(f\"Total review count: {total_review_count}\")\n",
    "    print(f\"Time elapsed: {end_pc - start_pc} seconds\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# scrape_steam_games(1000)\n",
    "scrape_steam_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3JmxUPQ1DKw"
   },
   "source": [
    "## MyAnimeList\n",
    "\n",
    "Scrapes the shows from `myanimelist_shows.txt` on https://myanimelist.net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4690,
     "status": "ok",
     "timestamp": 1743955029413,
     "user": {
      "displayName": "AAKASH MADISETTY",
      "userId": "05608679634229345476"
     },
     "user_tz": 240
    },
    "id": "9uReGIjk1JV-",
    "outputId": "3c8984e9-c55c-4656-9739-644eeac4cecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT module_path:  c:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\n",
      "Searching for anime: Shingeki no Kyojin\n",
      "Searching for anime: Spirited away\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Number of reviews is \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(review_list))\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Number of Animes used\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(anime_watched))\n\u001b[1;32m---> 77\u001b[0m \u001b[43mscrape_myanimelist_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m, in \u001b[0;36mscrape_myanimelist_reviews\u001b[1;34m(shows_file, out_file)\u001b[0m\n\u001b[0;32m     53\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# TOO many requests error\u001b[39;00m\n\u001b[0;32m     56\u001b[0m all_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 57\u001b[0m \u001b[43mfetch_animes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     59\u001b[0m     future_to_anime \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(fetch_animes): anime \u001b[38;5;28;01mfor\u001b[39;00m anime \u001b[38;5;129;01min\u001b[39;00m anime_list}\n",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m, in \u001b[0;36mscrape_myanimelist_reviews.<locals>.fetch_animes\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m     32\u001b[0m     reviews_url \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.jikan.moe/v4/anime/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manime_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/reviews?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m     review_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m review_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Stop if the request fails\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\http\\client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1430\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(\"INIT module_path: \", module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "DATA_DIR = module_path + \"/data\"\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def scrape_myanimelist_reviews(shows_file: str = \"myanimelist_shows.txt\", out_file: str = \"myanimelist_reviews.csv\"):\n",
    "    review_list = []  # Do not touch\n",
    "    anime_watched = []\n",
    "\n",
    "    # creating anime list\n",
    "    anime_list = []\n",
    "    with open(f\"{DATA_DIR}/{shows_file}\", \"r\") as file:\n",
    "        anime_list = file.read().splitlines()\n",
    "\n",
    "    print(\"Scraping MyAnimeList shows...\")\n",
    "    def fetch_animes():\n",
    "        for anime in anime_list:\n",
    "            print(f\"Searching for anime: {anime}\")\n",
    "            url = f\"https://api.jikan.moe/v4/anime?q={anime}&limit=1\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()  # Creates the Json\n",
    "            anime_id = data[\"data\"][0][\"mal_id\"]\n",
    "            for page in range(1, 6):\n",
    "                reviews_url = (\n",
    "                    f\"https://api.jikan.moe/v4/anime/{anime_id}/reviews?page={page}\"\n",
    "                )\n",
    "                review_response = requests.get(reviews_url)\n",
    "                if review_response.status_code != 200:\n",
    "                    break  # Stop if the request fails\n",
    "                # Enters the review portion of the code\n",
    "                reviews_data = review_response.json()[\"data\"]\n",
    "\n",
    "                for review in reviews_data:\n",
    "                    review_entry = {\n",
    "                        \"site\": \"MyAnimeList\",\n",
    "                        \"user\": review[\"user\"][\"username\"],\n",
    "                        \"review_target\": anime,\n",
    "                        \"review\": review[\"review\"],\n",
    "                        \"score\": review[\"score\"],\n",
    "                        \"max_score\": 10,\n",
    "                    }\n",
    "                    review_list.append(review_entry)\n",
    "                if anime not in anime_watched:\n",
    "                    anime_watched.append(anime)\n",
    "            time.sleep(2)  # TOO many requests error\n",
    "\n",
    "    fetch_animes()\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_anime = {executor.submit(fetch_animes): anime for anime in anime_list}\n",
    "        for future in as_completed(future_to_anime):\n",
    "            anime = future_to_anime[future]\n",
    "            try:\n",
    "                anime_reviews = future.result()\n",
    "                if anime_reviews:\n",
    "                    review_list.extend(anime_reviews)\n",
    "                    anime_watched.append(anime)\n",
    "            except Exception as e:\n",
    "                print(\"\")\n",
    "\n",
    "    df = pd.DataFrame(review_list)\n",
    "    df.to_csv(f\"{DATA_DIR}/{out_file}\", index=False)\n",
    "\n",
    "    print(df.head(380))\n",
    "    print(\"\\n Number of reviews: \", len(review_list))\n",
    "    print(\"\\n Number of Animes: \", len(anime_watched))\n",
    "\n",
    "scrape_myanimelist_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotten Tomatoes\n",
    "\n",
    "Scrapes the games from `rotten_tomatoes_movies.txt` on http://rottentomatoes.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT module_path:  c:\\Users\\Alan\\Desktop\\Open_Source\\BERT-TLSA-paper\n",
      "Scraping Rotten Tomatoes movies...\n",
      "Scraped movie: dune_2021 (20)\n",
      "Scraped movie: the_matrix (0)\n",
      "Scraped movie: inception (20)\n",
      "Scraped movie: interstellar_2014 (20)\n",
      "Scraped movie: the_dark_knight_2008 (0)\n",
      "Scraped movie: the_shawshank_redemption (0)\n",
      "Scraped movie: fight_club (20)\n",
      "Scraped movie: pulp_fiction (20)\n",
      "Scraped movie: forrest_gump (20)\n",
      "Scraped movie: the_godfather (20)\n",
      "Scraped movie: godfather_part_ii (20)\n",
      "Scraped movie: the_dark_knight_rises (20)\n",
      "Scraped movie: schindlers_list (20)\n",
      "Scraped movie: the_lord_of_the_rings_the_return_of_the_king_2003 (0)\n",
      "Scraped movie: x_men_days_of_future_past (20)\n",
      "Scraped movie: x_men_apocalypse (20)\n",
      "Scraped movie: toxic_avenger (20)\n",
      "Scraped movie: big_hero_6 (20)\n",
      "Scraped movie: last_days_in_vietnam (20)\n",
      "Scraped movie: barbie (20)\n",
      "Scraped movie: marvels_the_avengers (20)\n",
      "Scraped movie: big (20)\n",
      "Scraped movie: dil-chahta-hai (20)\n",
      "Scraped movie: the_incredible_hulk (20)\n",
      "Scraped movie: oppenheimer_2023 (20)\n",
      "Scraped movie: the_call_2020_kr (20)\n",
      "Scraped movie: the_40_year_old_virgin (20)\n",
      "Scraped movie: tmnt_2007 (20)\n",
      "Scraped movie: sing_2016 (20)\n",
      "Scraped movie: harry_potter_and_the_sorcerers_stone (20)\n",
      "Scraped movie: world-war-z (20)\n",
      "Scraped movie: teenage_mutant_ninja_turtles_mutant_mayhem (20)\n",
      "Scraped movie: spider_man_across_the_spider_verse (20)\n",
      "Scraped movie: spider_man_into_the_spider_verse (20)\n",
      "Scraped movie: spider_man_no_way_home (20)\n",
      "Scraped movie: top_gun_maverick (20)\n",
      "Scraped movie: hes_just_not_that_into_you (20)\n",
      "Scraped movie: cal (6)\n",
      "Scraped movie: inside_out_2015 (20)\n",
      "Scraped movie: insidious_the_red_door (20)\n",
      "Scraped movie: insidious (20)\n",
      "Scraped movie: smile_2022 (20)\n",
      "Scraped movie: paper_towns (20)\n",
      "Scraped movie: to_all_the_boys_ive_loved_before (20)\n",
      "Scraped movie: talk_to_me_2023 (20)\n",
      "Scraped movie: 1017776-rocky (20)\n",
      "Scraped movie: rocky_iv (20)\n",
      "Scraped movie: karate_kid (20)\n",
      "Scraped movie: star_wars_episode_iii_revenge_of_the_sith (20)\n",
      "Scraped movie: star_wars_episode_vii_the_force_awakens (20)\n",
      "Scraped movie: joker_folie_a_deux (20)\n",
      "Scraped movie: handsome_devil (20)\n",
      "Scraped movie: the_take_2016 (20)\n",
      "Scraped movie: get_out (20)\n",
      "Scraped movie: the_super_mario_bros_movie (20)\n",
      "Scraped movie: a_minecraft_movie (20)\n",
      "Scraped movie: border_2018 (20)\n",
      "Scraped movie: wild_at_heart (20)\n",
      "Scraped movie: the_suicide_squad (20)\n",
      "Scraped movie: madea_goes_to_jail (20)\n",
      "Scraped movie: fantastic_four (20)\n",
      "Scraped movie: iron_man (20)\n",
      "Scraped movie: iron_giant (20)\n",
      "Scraped movie: eat_pray_love (20)\n",
      "Scraped movie: the_lego_ninjago_movie (20)\n",
      "Scraped movie: waste-land (20)\n",
      "Scraped movie: land_of_the_dead (20)\n",
      "Scraped movie: birdman_2014 (20)\n",
      "Scraped movie: creed_2015 (20)\n",
      "Scraped movie: pirates_of_the_caribbean_the_curse_of_the_black_pearl (20)\n",
      "Scraped movie: monsters_inc (20)\n",
      "Scraped movie: shadow_in_the_cloud (20)\n",
      "Scraped movie: kingdom_of_the_planet_of_the_apes (20)\n",
      "Scraped movie: wreck_it_ralph (20)\n",
      "Scraped movie: mortal_kombat_2021 (20)\n",
      "Scraped movie: sausage_party (20)\n",
      "Scraped movie: 1066050-party_girl (20)\n",
      "Scraped movie: mortal_kombat (20)\n",
      "Scraped movie: et_the_extraterrestrial (20)\n",
      "Scraped movie: dont_say_a_word (20)\n",
      "Scraped movie: fifty_shades_of_grey (20)\n",
      "Scraped movie: bagman_2024 (20)\n",
      "Scraped movie: the_good_the_bad_and_the_ugly (20)\n",
      "Scraped movie: good_shepherd (20)\n",
      "Scraped movie: 1032176-goodfellas (20)\n",
      "Scraped movie: seven (20)\n",
      "Scraped movie: deadpool (20)\n",
      "Scraped movie: its_a_wonderful_life (20)\n",
      "Scraped movie: pitch_perfect (20)\n",
      "Scraped movie: silence_of_the_lambs (20)\n",
      "Scraped movie: seven_samurai_1956 (20)\n",
      "Scraped movie: saving_private_ryan (20)\n",
      "Scraped movie: city_of_god (20)\n",
      "Scraped movie: green_mile (20)\n",
      "Scraped movie: 1084398-life_is_beautiful (20)\n",
      "Scraped movie: terminator_2_judgment_day (20)\n",
      "Scraped movie: terminator (20)\n",
      "Scraped movie: stargate_the_ark_of_truth (20)\n",
      "Scraped movie: back_to_the_future (20)\n",
      "Scraped movie: back_to_the_future (20)\n",
      "Scraped movie: pianist (20)\n",
      "Scraped movie: gladiator (20)\n",
      "Scraped movie: parasite_2019 (20)\n",
      "Scraped movie: american_psycho (20)\n",
      "Scraped movie: the_lion_king (20)\n",
      "Scraped movie: grave_of_the_fireflies (20)\n",
      "Scraped movie: departed (20)\n",
      "Scraped movie: whiplash_2014 (20)\n",
      "Scraped movie: harakiri (20)\n",
      "Scraped movie: american_history_x (20)\n",
      "Scraped movie: prestige (20)\n",
      "Scraped movie: leon_the_professional (20)\n",
      "Scraped movie: 1003707-casablanca (20)\n",
      "Scraped movie: the_great_gatsby_2013 (20)\n",
      "Scraped movie: usual_suspects (20)\n",
      "Scraped movie: untouchables (20)\n",
      "Scraped movie: cinema_paradiso (20)\n",
      "Scraped movie: alien (20)\n",
      "Scraped movie: modern_times (20)\n",
      "Scraped movie: once_upon_a_time_in_hollywood (20)\n",
      "Scraped movie: django_unchained_2012 (20)\n",
      "Scraped movie: city_lights (20)\n",
      "Scraped movie: apocalypse_now (20)\n",
      "Scraped movie: memento (20)\n",
      "Scraped movie: wall_e (20)\n",
      "Scraped movie: raiders_of_the_lost_ark (20)\n",
      "Scraped movie: the_lives_of_others (20)\n",
      "Scraped movie: avengers_infinity_war (20)\n",
      "Scraped movie: sunset_boulevard (20)\n",
      "Scraped movie: paths_of_glory (20)\n",
      "Scraped movie: witness_for_the_prosecution (20)\n",
      "Scraped movie: shining (20)\n",
      "Scraped movie: great_dictator (20)\n",
      "Scraped movie: 12th_fail (20)\n",
      "Scraped movie: quel_maledetto_treno_blindato (20)\n",
      "Scraped movie: coco_2017 (20)\n",
      "Scraped movie: amadeus (20)\n",
      "Scraped movie: toy_story (20)\n",
      "Scraped movie: good_will_hunting (20)\n",
      "Scraped movie: oldboy (20)\n",
      "Scraped movie: doctor_strange_in_the_multiverse_of_madness (20)\n",
      "Scraped movie: das_boot (20)\n",
      "Scraped movie: american_beauty (20)\n",
      "Scraped movie: a_brave_heart_the_lizzie_velasquez_story (20)\n",
      "Scraped movie: 1065684-braveheart (20)\n",
      "Scraped movie: princess_mononoke (20)\n",
      "Scraped movie: your_name_2017 (20)\n",
      "Scraped movie: high_and_low (20)\n",
      "Scraped movie: 3_idiots (20)\n",
      "Scraped movie: front_of_the_class (16)\n",
      "Scraped movie: once_upon_a_time_in_america (20)\n",
      "Scraped movie: capernaum (20)\n",
      "Scraped movie: singin_in_the_rain (20)\n",
      "Scraped movie: come_and_see (20)\n",
      "Scraped movie: requiem_for_a_dream (20)\n",
      "Scraped movie: toy_story_3 (20)\n",
      "Scraped movie: the_hunt_2019 (20)\n",
      "Scraped movie: ikiru (20)\n",
      "Scraped movie: eternal_sunshine_of_the_spotless_mind (20)\n",
      "Scraped movie: 2001_a_space_odyssey (20)\n",
      "Scraped movie: reservoir_dogs (20)\n",
      "Scraped movie: 1001115-apartment (20)\n",
      "Scraped movie: incendies (20)\n",
      "Scraped movie: lawrence_of_arabia (20)\n",
      "Scraped movie: scarface (20)\n",
      "Scraped movie: double_indemnity (20)\n",
      "Scraped movie: the_heat (20)\n",
      "Scraped movie: north_by_northwest (20)\n",
      "Scraped movie: citizen_kane (20)\n",
      "Scraped movie: up (20)\n",
      "Scraped movie: 1012928-m (20)\n",
      "Scraped movie: full_metal_jacket (20)\n",
      "Scraped movie: vertigo (20)\n",
      "Scraped movie: amelie (20)\n",
      "Scraped movie: a_separation_2011 (20)\n",
      "Scraped movie: to_kill_a_mockingbird (20)\n",
      "Scraped movie: clockwork_orange (20)\n",
      "Scraped movie: like_stars_on_earth (20)\n",
      "Scraped movie: die_hard (20)\n",
      "Scraped movie: 1020130-sting (20)\n",
      "Scraped movie: indiana_jones_and_the_dial_of_destiny (20)\n",
      "Scraped movie: metropolis_2001 (20)\n",
      "Scraped movie: snatch (20)\n",
      "Scraped movie: 1917_2019 (20)\n",
      "Scraped movie: la_confidential (20)\n",
      "Scraped movie: bicycle_thieves (20)\n",
      "Scraped movie: downfall (20)\n",
      "Scraped movie: dangal (20)\n",
      "Scraped movie: the_wolf_of_wall_street_2013 (20)\n",
      "Scraped movie: taxi_driver (20)\n",
      "Scraped movie: hamilton_2020 (20)\n",
      "Scraped movie: green_book (20)\n",
      "Scraped movie: for_a_few_dollars_more (20)\n",
      "Scraped movie: truman_show (20)\n",
      "Scraped movie: some_like_it_hot (20)\n",
      "Scraped movie: 1198124-shutter_island (20)\n",
      "Scraped movie: the_kid_2019 (20)\n",
      "Scraped movie: the_father_2021 (20)\n",
      "Scraped movie: 1000626-all_about_eve (20)\n",
      "Scraped movie: jurassic_park (20)\n",
      "Scraped movie: there_will_be_water (0)\n",
      "Scraped movie: 1067987-casino (20)\n",
      "Scraped movie: sixth_sense (20)\n",
      "Scraped movie: ran (20)\n",
      "Scraped movie: no_country_for_old_men (20)\n",
      "Scraped movie: 1021244-thing (20)\n",
      "Scraped movie: pans_labyrinth (20)\n",
      "Scraped movie: 1041911-unforgiven (20)\n",
      "Scraped movie: beautiful_mind (20)\n",
      "Scraped movie: kill_bill_vol_1 (20)\n",
      "Scraped movie: treasure_of_the_sierra_madre (20)\n",
      "Scraped movie: prisoners_2013 (20)\n",
      "Scraped movie: yojimbo (20)\n",
      "Scraped movie: finding_nemo (20)\n",
      "Scraped movie: the_great_escape (20)\n",
      "               site       user review_target  \\\n",
      "0   Rotten Tomatoes     Juan P     Dune 2021   \n",
      "1   Rotten Tomatoes      Hex x     Dune 2021   \n",
      "2   Rotten Tomatoes                Dune 2021   \n",
      "3   Rotten Tomatoes  xpig332 B     Dune 2021   \n",
      "4   Rotten Tomatoes    Frans B     Dune 2021   \n",
      "..              ...        ...           ...   \n",
      "95  Rotten Tomatoes   Julius B  Pulp Fiction   \n",
      "96  Rotten Tomatoes             Pulp Fiction   \n",
      "97  Rotten Tomatoes    Saleh S  Pulp Fiction   \n",
      "98  Rotten Tomatoes     Jack S  Pulp Fiction   \n",
      "99  Rotten Tomatoes     Laze T  Pulp Fiction   \n",
      "\n",
      "                                               review score  max_score  \n",
      "0   Una obra de arte dirigida por Denis Villeneuve...     4          5  \n",
      "1   Took me a while to get into it, but as someone...   3.5          5  \n",
      "2   This might be my favorite movie !\\nDune (2021)...     5          5  \n",
      "3   Extremely slow & boring, most action occurs in...   1.5          5  \n",
      "4   Exceptional, wildly fantastic and never a dull...     5          5  \n",
      "..                                                ...   ...        ...  \n",
      "95  This is the Exact movie I was looking for, 90'...     5          5  \n",
      "96  Samuel Jackson makes the entire film breathe l...     5          5  \n",
      "97  Absolutel cinema , another movie from tarantin...     5          5  \n",
      "98                          Best movie of all time!!!     5          5  \n",
      "99  Its just a well produced movie, just really we...     5          5  \n",
      "\n",
      "[100 rows x 6 columns]\n",
      "Number of reviews:  4182\n",
      "Number of movies:  215\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(\"INIT module_path: \", module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "DATA_DIR = module_path + \"/data\"\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "\n",
    "def scrape_rotten_tomatoes_reviews(movies_file: str = \"rotten_tomatoes_movies.txt\", out_file: str = \"rotten_tomatoes_reviews.csv\"):\n",
    "    all_text = []\n",
    "\n",
    "    def determine_name(movie):\n",
    "        formatted_string = movie.replace('_', ' ').title()\n",
    "        return formatted_string\n",
    "\n",
    "    with open(f\"{DATA_DIR}/{movies_file}\", \"r\") as file:\n",
    "        movies = file.read().splitlines()\n",
    "\n",
    "    print(\"Scraping Rotten Tomatoes movies...\")\n",
    "    for movie in movies:\n",
    "        url = f\"https://www.rottentomatoes.com/m/{movie}/reviews?type=user\"\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        divs = soup.find_all('div', {'class': 'audience-review-row'}) \n",
    "        curr_review_count = 0\n",
    "        for x, block in enumerate(divs[:200],start = 1):\n",
    "            review_block = block.find('p',class_ = \"audience-reviews__review\")\n",
    "            score_block = block.find('rating-stars-group')\n",
    "            reviewer_block = block.find('a', class_='audience-reviews__name')\n",
    "            \n",
    "            review = review_block.get_text(strip=True) if review_block else \"No review text\"    \n",
    "            reviewer = reviewer_block.get_text(strip=True) if reviewer_block else \" \"\n",
    "            score = score_block.get('score') if score_block else \" \"\n",
    "            entry = {\n",
    "                'site': \"Rotten Tomatoes\",\n",
    "                'user': reviewer ,    \n",
    "                'review_target': determine_name(movie),    \n",
    "                'review': review,\n",
    "                'score': score,  \n",
    "                'max_score': 5   \n",
    "            }\n",
    "            curr_review_count += 1\n",
    "            all_text.append(entry)\n",
    "        print(f\"Scraped movie: {movie} ({curr_review_count})\")\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(all_text)\n",
    "    df.to_csv(f\"{DATA_DIR}/{out_file}\", index=False)\n",
    "\n",
    "    print(df.head(100))\n",
    "    print(\"Number of reviews: \", len(all_text))\n",
    "    print(\"Number of movies: \", len(movies))\n",
    "\n",
    "scrape_rotten_tomatoes_reviews()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
